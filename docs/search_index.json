[["index.html", "BioDIGS: Exploring Soil Data About this Book 0.1 Target Audience 0.2 Platform 0.3 Data", " BioDIGS: Exploring Soil Data February 21, 2025 About this Book This is a companion training guide for BioDIGS, a GDSCN project that brings a research experience into the classroom. This activity guides students through exploration of the BioDIGS soil data using the tidyverse in R. Students will learn basic data summarization, visualization, and mapping skills. Visit the BioDIGS (BioDiversity and Informatics for Genomics Scholars) website here for more information about this collaborative, distributed research project, including how you can get involved! The GDSCN (Genomics Data Science Community Network) is a consortium of educators who aim to create a world where researchers, educators, and students from diverse backgrounds are able to fully participate in genomic data science research. You can find more information about its mission and initiatives here. 0.1 Target Audience The activities in this guide are written for undergraduate students and beginning graduate students. Some sections require basic understanding of the R programming language, which is indicated at the beginning of the chapter. 0.2 Platform The activities in this guide are demonstrated on NHGRI’s AnVIL cloud computing platform. AnVIL is the preferred computing platform for the GDSCN. However, all of these activities can be done using your personal installation of R or using the online Galaxy portal. 0.3 Data The data generated by the BioDIGS project is available through the BioDIGS website, as well as through an AnVIL workspace. Data about the soil itself as well as soil metal content was generated by the Delaware Soil Testing Program at the University of Delaware. Sequences were generated by the Johns Hopkins University Genetic Resources Core Facility and by PacBio. "],["background.html", "Chapter 1 Background 1.1 What is genomics? 1.2 What is data science? 1.3 What is cloud computing? 1.4 Why soil microbes? 1.5 Heavy metals and human health", " Chapter 1 Background One critical aspect of an undergraduate STEM education is hands-on research. Undergraduate research experiences enhance what students learn in the classroom as well as increase a student’s interest in pursuing STEM careers (Russell, Hancock, and McCullough 2007). It can also lead to improved scientific reasoning and increased academic performance overall (Buffalari et al. 2020). However, many students at underresourced institutions like community colleges, Historically Black Colleges and Universities (HBCUs), tribal colleges and universities, and Hispanic-serving institutions have limited access to research opportunities compared to their cohorts at larger four-year colleges and R1 institutions. These students are also more likely to belong to groups that are already under-represented in STEM disciplines, particularly genomics and data science (Canner et al. 2017; GDSCN 2022). The BioDIGS Project aims to be at the intersection of genomics, data science, cloud computing, and education. 1.1 What is genomics? Genomics broadly refers to the study of genomes, which are an organism’s complete set of DNA. This includes both genes and non-coding regions of DNA. Traditional genomics involves sequencing and analyzing the genome of individual species. Metagenomics expands genomics to look at the collective genomes of entire communities of organisms in an environmental sample, like soil. It allows researchers to study not just the genes of culturable or isolated organisms, but the entirety of genetic material present in a given environment. By using genomic techniques to survey the soil microbes, we can identify everything in the soil, including microbes that no one has identified before. We are doing both traditional genomics and metagenomics as part of BioDIGS. 1.2 What is data science? Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data. It includes collecting, cleaning, and combining data from multiple databases, exploring data and developing statistical and machine learning models to identify patterns in complex datasets, and creating tools to efficiently store, process, and access large amounts of data. 1.3 What is cloud computing? Cloud computing just means using the internet to get access to powerful computer resources like storage, servers, databases, networking tools, and specialized software programs. Instead of having to buy and maintain their own powerful computers, storage servers, and other systems, users can pay to use them through an internet connection as needed. Users only pay for what they need, when they actually use it, and professionals update and maintain the systems in large data centers. It is a particularly useful tool for researchers and students at smaller institutions with limited computational services, especially when working with complex databases. The genome assembly and analyses for BioDIGS have been done using the NHGRI AnVIL cloud computing platform, as well as Galaxy. 1.4 Why soil microbes? It can be challenging to include undergraduates in human genomic and health research, especially in a classroom context. Both human genetic data and human health data are protected data, which limits the sort of information students can access without undergoing specialized ethics training. However, the same sorts of data cleaning and analysis methods used for human genomic data are also used for microbial genomic data, which does not have the same sort of legal protections as human genetic data. This makes it ideal for training undergraduate students at the beginning of their careers and can be used to prepare students for future research in human genomics and health (Jurkowski, Reid, and Labov 2017). Additionally, the microbes in the soil can have big impacts on our health (Brevik and Burgess 2014). 1.5 Heavy metals and human health Human activities that change the landscape can also change what sorts of inorganic and abiotic compounds we find in the soil, particularly increasing the amount of heavy metals (Yan et al. 2020). When cars drive on roads, compounds from the exhaust, oil, and other fluids might settle onto the roads and be washed into the soil. When we put salt on roads, parking lots, and sidewalks, the salts themselves will eventually be washed away and enter the ecosystem through both water and soil. Chemicals from factories and other businesses also leech into our environment. Previous research has demonstrated that in areas with more human activity, like cities, soils include greater concentrations of heavy metals than found in rural areas with limited human populations (Khan et al. 2023; Wang, Birch, and Liu 2022). Increased heavy metal concentrations also disproportionately affect lower-income and predominantly minority areas (Jones et al. 2022). Research suggests that increased heavy metal concentration in soils has major impacts on the soil microbial community. In particular, increased heavy metal concentration is associated with an increase in soil bacteria that have antibiotic resistance markers (Gorovtsov, Sazykin, and Sazykina 2018; Nguyen et al. 2019; Sun, Xu, and Fan 2021). References "],["research-team.html", "Chapter 2 Research Team 2.1 Soil sampling", " Chapter 2 Research Team This project is coordinated by the Genomics Data Science Community Network (GDSCN). You can read more about the GDSCN and its mission at the network website. 2.1 Soil sampling This map shows the current sampling locations for the BioDIGS project. The extensive network of the GDSCN has made this data collection possible. Soil sampling for this project was done by both faculty and student volunteers from schools that aren’t traditional R1 research institutions. Many of the faculty are also members of the GDSCN. This list of locations reflects GDSCN institutions and friends of GDSCN who have collected soil samples. Annandale, VA: Northern Virginia Community College Atlanta, GA: Spelman College Baltimore, MD: College of Southern Maryland, Notre Dame College of Maryland, Towson University Bismark, ND: United Tribes Technical College El Paso, TX: El Paso Community College, The University of Texas at El Paso Fresno, CA: Clovis Community College Greensboro, NC: North Carolina A&amp;T State University Harrisonburg, VA: James Madison University Honolulu, Hawai’i: University of Hawai’i at Mānoa Las Cruces, NM: Doña Ana Community College Montgomery County, MD: Montgomery College, Towson University Nashville, TN: Meharry Medical College New York, NY: Guttman Community College CUNY Petersburg, VA: Virginia State University Seattle, WA: North Seattle College, Pierce College Tsaile, AZ: Diné College "],["support.html", "Chapter 3 Support 3.1 Funding 3.2 Sponsors 3.3 Analytical and Computational Support", " Chapter 3 Support This project would not be possible without financial and technical support from many organizations and people. 3.1 Funding Funding for this project has been provided by the National Human Genome Research Institute (Contract # 75N92022P00232 awarded to Johns Hopkins University). 3.2 Sponsors PacBio and CosmosID have graciously donated supplies. Advances in Genome Biology and Technology provided funding support for several team members to attend AGBT 2024. 3.3 Analytical and Computational Support Computational support has been provided by NHGRI’s AnVIL cloud computing platform and Galaxy. "],["biodigs-data.html", "Chapter 4 BioDIGS Data 4.1 Sample Metadata 4.2 Soil Property Data 4.3 Genomics and Metagenomics Data and Metadata 4.4 BioDIGSData R package", " Chapter 4 BioDIGS Data There are currently three major kinds of data available from BioDIGS: sample metadata, soil testing data, and genomics and metagenomics data. All of these are available for use in your classroom. 4.1 Sample Metadata This dataset contains information about the samples themselves, including GPS coordinates for the sample location, date the sample was taken, and the site name. This dataset is also available from the BioDIGS website You can also see images of each sampling site and soil characteristics at the sample map. 4.2 Soil Property Data This dataset includes basic information about the soil itself like pH, percentage of organic matter, variety of soil metal concentrations. The complete data dictionary is available here. The dataset is available at the BioDIGS website. This dataset was generated by the Delaware Soil Testing Program at the University of Delaware. 4.3 Genomics and Metagenomics Data and Metadata In the future, you will be able to access this data in both raw and processed forms. The Illumina and Nanopore sequences were generated at the Johns Hopkins University Genetic Resources Core Facility. PacBio sequencing was done by PacBio directly. More information coming soon! 4.4 BioDIGSData R package We’ve created a data package to help you easily bring BioDIGS soil data and metadata into R! This package is currently in development, so if there’s a feature you’d like to see, please let us know! The most up-to-date version of the package can be accessed via GitHub at https://github.com/fhdsl/BioDIGSData 4.4.1 Installation Install the package by running the following in R. You might need to install the devtools package. devtools::install_github(&quot;fhdsl/BioDIGSData&quot;) 4.4.2 Usage Bring in the data using predefined functions. For example: # Load soil property data my_data &lt;- BioDIGSData::BioDIGS_soil_data() # Load site metadata my_data &lt;- BioDIGSData::BioDIGS_metadata() # Load DNA metadata my_data &lt;- BioDIGSData::BioDIGS_DNA_conc_data() "],["notes-about-the-activity.html", "Chapter 5 Notes about the Activity", " Chapter 5 Notes about the Activity Coming soon! "],["additional-lecture-material.html", "Chapter 6 Additional Lecture Material", " Chapter 6 Additional Lecture Material Coming soon! "],["using-anvil.html", "Chapter 7 Using AnVIL", " Chapter 7 Using AnVIL This activity was designed to work on local installations of RStudio, Posit cloud, or using NHGRI’s cloud computing platform AnVIL. If you’d like to get started with using AnVIL in the classroom, checkout the AnVIL Instructor’s Guide. This guide includes information on setting up billing, using premade content (or developing your own), and managing costs. There are also details guides on exploring and using AnVIL for students. "],["introduction.html", "Chapter 8 Introduction 8.1 Before You Start 8.2 Objectives", " Chapter 8 Introduction In this activity, you’ll have a chance to become familiar with the BioDIGS soil testing data. This dataset includes information on the inorganic components of each soil sample, particularly metal concentrations. Human activity can increase the concentration of inorganic compounds in the soil. When cars drive on roads, compounds from the exhaust, oil, and other fluids might settle onto the roads and be washed into the soil. When we put salt on roads, parking lots, and sidewalks, the salts themselves will eventually be washed away and enter the ecosystem through both water and soil. Chemicals from factories and other businesses also leech into our environment. All of this means the concentration of heavy metals and other chemicals will vary among the soil samples collected for the BioDIGS project. 8.1 Before You Start If you do not already have a Google account that you would like to use for accessing Terra, create one now. If you would like to create a Google account that is associated with your non-Gmail, institutional email address, follow these instructions. 8.2 Objectives This activity will teach you how to use the AnVIL platform to: Open data from an R package Examine objects in R Calculate summary statistics for variables in the soil testing data Create and interpret histograms and boxplots for variables in the soil testing data "],["part-1.-examining-the-data.html", "Chapter 9 Part 1. Examining the Data", " Chapter 9 Part 1. Examining the Data We will use the BioDIGS package to retrieve the data. We first need to install the package from where it is stored on GitHub. devtools::install_github(&quot;fhdsl/BioDIGSData&quot;) Once you’ve installed the package, we can load the library and assign the soil testing data to an object. This command follows the code structure: dataset_object_name &lt;- stored_BioDIGS_dataset library(BioDIGSData) soil.values &lt;- BioDIGS_soil_data() It seems like the dataset loaded, but it’s always a good idea to verify. There are many ways to check, but the easiest approach (if you’re using RStudio) is to look at the Environment tab on the upper right-hand side of the screen. You should now have an object called soil.values that includes some number of observations for 28 variables. The observations refer to the number of rows in the dataset, while the variables tell you the number of columns. As long as neither the observations or variables are 0, you can be confident that your dataset loaded. Let’s take a quick look at the dataset. We can do this by clicking on soil.values object in the Environment tab. (Note: this is equivalent to typing View(soil.values) in the R console.) This will open a new window for us to scroll through the dataset. Well, the data definitely loaded, but those column names aren’t immediately understandable. What could As_EPA3051 possibly mean? In addition to the dataset, we need to load the data dictionary as well. Data dictionary: a file containing the names, definitions, and attributes about data in a database or dataset. In this case, the data dictionary can help us make sense of what sort of values each column represents. The data dictionary for the BioDIGS soil testing data is available in the R package (see code below), but we have also reproduced it here. ?BioDIGS_soil_data() site_id Unique letter and number site name full_name Full site name As_EPA3051 Arsenic (mg/kg), EPA Method 3051A. Quantities &lt; 3.0 are not detectable. Cd_EPA3051 Cadmium (mg/kg), EPA Method 3051A. Quantities &lt; 0.2 are not detectable. Cr_EPA3051 Chromium (mg/kg), EPA Method 3051A Cu_EPA3051 Copper (mg/kg), EPA Method 3051A Ni_EPA3051 Nickel (mg/kg), EPA Method 3051A Pb_EPA3051 Lead (mg/kg), EPA Method 3051A Zn_EPA3051 Zinc (mg/kg), EPA Method 3051A water_pH A-E_Buffer_pH OM_by_LOI_pct Organic Matter by Loss on Ignition P_Mehlich3 Phosphorus (mg/kg), using the Mehlich 3 soil test extractant K_Mehlich3 Potassium (mg/kg), using the Mehlich 3 soil test extractant Ca_Mehlich3 Calcium (mg/kg), using the Mehlich 3 soil test extractant Mg_Mehlich3 Magnesium (mg/kg), using the Mehlich 3 soil test extractant Mn_Mehlich3 Manganese (mg/kg), using the Mehlich 3 soil test extractant Zn_Mehlich3 Zinc (mg/kg), using the Mehlich 3 soil test extractant Cu_Mehlich3 Copper (mg/kg), using the Mehlich 3 soil test extractant Fe_Mehlich3 Iron (mg/kg), using the Mehlich 3 soil test extractant B_Mehlich3 Boron (mg/kg), using the Mehlich 3 soil test extractant S_Mehlich3 Sulfur (mg/kg), using the Mehlich 3 soil test extractant Na_Mehlich3 Sodium (mg/kg), using the Mehlich 3 soil test extractant Al_Mehlich3 Aluminum (mg/kg), using the Mehlich 3 soil test extractant Est_CEC Cation Exchange Capacity (meq/100g) at pH 7.0 (CEC) Base_Sat_pct Base saturation (BS). This represents the percentage of CEC occupied by bases (Ca2+, Mg2+, K+, and Na+). The %BS increases with increasing soil pH. The availability of Ca2+, Mg2+, and K+ increases with increasing %BS. P_Sat_ratio Phosphorus saturation ratio. This is the ratio between the amount of phosphorus present in the soil and the total capacity of that soil to retain phosphorus. The ability of phosphorus to be bound in the soil is primary a function of iron (Fe) and aluminum (Al) content in that soil. Using the data dictionary, we find that the values in column As_EPA3051 give us the arsenic concentration in mg/kg of each soil sample, as determined by EPA Method 3051A. This method uses a combination of heat and acid to extract specific elements (like arsenic, cadmium, chromium, copper, nickel, lead, and zinc) from soil samples. While arsenic can occur naturally in soils, higher levels suggest the soil may have been contaminated by mining, hazardous waste, or pesticide application. Arsenic is toxic to humans. QUESTIONS: What data is found in the column labeled “Fe_Mehlich3”? Why would we be interested how much of this is in the soil? (You may have to search the internet for this answer.) What data is found in the column labeled “Base_Sat_pct”? What does this variable tell us about the soil? We can also look at just the names of all the columns using the R console using the colnames() command. colnames(soil.values) ## [1] &quot;site_id&quot; &quot;site_name&quot; &quot;type&quot; &quot;As_EPA3051&quot; ## [5] &quot;Cd_EPA3051&quot; &quot;Cr_EPA3051&quot; &quot;Cu_EPA3051&quot; &quot;Ni_EPA3051&quot; ## [9] &quot;Pb_EPA3051&quot; &quot;Zn_EPA3051&quot; &quot;water_pH&quot; &quot;OM_by_LOI_pct&quot; ## [13] &quot;P_Mehlich3&quot; &quot;K_Mehlich3&quot; &quot;Ca_Mehlich3&quot; &quot;Mg_Mehlich3&quot; ## [17] &quot;Mn_Mehlich3&quot; &quot;Zn_Mehlich3&quot; &quot;Cu_Mehlich3&quot; &quot;Fe_Mehlich3&quot; ## [21] &quot;B_Mehlich3&quot; &quot;S_Mehlich3&quot; &quot;Na_Mehlich3&quot; &quot;Al_Mehlich3&quot; ## [25] &quot;Est_CEC&quot; &quot;Base_Sat_pct&quot; &quot;P_Sat_ratio&quot; &quot;region&quot; Most of the column names are found in the data dictionary, but the very last column (“region”) isn’t. How peculiar! Let’s look at what sort of values this particular column contains. The tab with the table of the soil.views object should still be open in the upper left pane of the RStudio window. If not, you can open it again by clicking on soils.view in the Environment pane, or by using the View() command. View(soil.values) If you scroll to the end of the table, we can see that “region” seems to refer to the city or area where the samples were collected. For example, the first 6 samples all come from Baltimore City. You may notice that some cells in the soil.values table contain NA. This just means that the soil testing data for that sample isn’t available yet. We’ll take care of those values in the next part. QUESTIONS: How many observations are in the soil testing values dataset that you loaded? What do each of these observations refer to? How many different regions are represented in the soil testing dataset? How many of them have soil testing data available? "],["part-2.-summarizing-the-data-with-statistics.html", "Chapter 10 Part 2. Summarizing the Data with Statistics", " Chapter 10 Part 2. Summarizing the Data with Statistics Now that we have the dataset loaded, let’s explore the data in more depth. First, we should remove those samples that don’t have soil testing data yet. We could keep them in the dataset, but removing them at this stage will make the analysis a little cleaner. In this case, as we know the reason the data are missing (and that reason will not skew our analysis), we can safely remove these samples. This will not be the case for every data analysis. We can remove the unanalyzed samples using the drop_na() function from the tidyr package. This function removes any rows from a table that contains NA for a particular column. This command follows the code structure: dataset_new_name &lt;- dataset %&gt;% drop_na(column_name) The `%&gt;% is called a pipe and it tells R that the commands after it should all be applied to the object in front of it. (In this case, we can filter out all samples missing a value for “As_EPA3051” as a proxy for samples without soil testing data.) library(tidyr) soil.values.clean &lt;- soil.values %&gt;% drop_na(As_EPA3051) Great! Now let’s calculate some basic statistics. For example, we might want to know what the mean (average) arsenic concentration is for all the soil samples. We can use a combination of two functions: pull() and mean(). pull() lets you extract a column from your table for statistical analysis, while mean() calculates the average value for the extracted column. This command follows the code structure: OBJECT %&gt;% pull(column_name) %&gt;% mean() pull() is a command from the tidyverse package, so we’ll need to load that library before our command. library(tidyverse) soil.values.clean %&gt;% pull(As_EPA3051) %&gt;% mean() ## [1] 5.10875 We can run similar commands to calculate the standard deviation (sd), minimum (min), and maximum (max) for the soil arsenic values. soil.values.clean %&gt;% pull(As_EPA3051) %&gt;% sd() ## [1] 5.606926 soil.values.clean %&gt;% pull(As_EPA3051) %&gt;% min() ## [1] 0 soil.values.clean %&gt;% pull(As_EPA3051) %&gt;% max() ## [1] 27.3 The soil testing dataset contains samples from multiple geographic regions, so maybe it’s more meaningful to find out what the average arsenic values are for each region. We have to do a little bit of clever coding trickery for this using the group_by and summarize functions. First, we tell R to split our dataset up by a particular column (in this case, region) using the group_by function, then we tell R to summarize the mean arsenic concentration for each group. When using the summarize function, we tell R to make a new table (technically, a tibble in R) that contains two columns: the column used to group the data and the statistical measure we calculated for each group. This command follows the code structure: dataset %&gt;% group_by(column_name) %&gt;% summarize(mean(column_name)) soil.values.clean %&gt;% group_by(region) %&gt;% summarize(mean(As_EPA3051)) ## # A tibble: 2 × 2 ## region `mean(As_EPA3051)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Baltimore City 5.56 ## 2 Montgomery County 4.66 Now we know that the mean arsenic concentration might be different for each region. If we compare the samples from Baltimore City and Montgomery County, the Baltimore City samples appear to have a higher mean arsenic concentration than the Montgomery County samples. QUESTIONS: All the samples from Baltimore City and Montgomery County were collected from public park land. The parks sampled from Montgomery County were located in suburban and rural areas, compared to the urban parks sampled in Baltimore City. Why might the Montgomery County samples have a lower average arsenic concentration than the samples from Baltimore City? What is the mean iron concentration for samples in this dataset? What about the standard deviation, minimum value, and maximum value? Calculate the mean iron concentration by region. Which region has the highest mean iron concentration? What about the lowest? Let’s say we’re interested in looking at mean concentrations that were determined using EPA Method 3051. Given that there are 8 of these measures in the soil.values dataset, it would be time consuming to run our code from above for each individual measure. We can add two arguments to our summarize statement to calculate statistical measures for multiple columns at once: the across argument, which tells R to apply the summarize command to multiple columns; and the ends_with parameter, which tells R which columns should be included in the statistical calculation. We are using ends_with because for this question, all the columns that we’re interested in end with the string ‘EPA3051’. This command follows the code structure: dataset %&gt;% group_by(column_name) %&gt;% summarize(across(ends_with(common_column_name_ending), mean)) soil.values.clean %&gt;% group_by(region) %&gt;% summarize(across(ends_with(&#39;EPA3051&#39;), mean)) ## # A tibble: 2 × 8 ## region As_EPA3051 Cd_EPA3051 Cr_EPA3051 Cu_EPA3051 Ni_EPA3051 Pb_EPA3051 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Baltimore C… 5.56 0.359 34.5 35.0 17.4 67.2 ## 2 Montgomery … 4.66 0.402 29.9 24.3 23.4 38.7 ## # ℹ 1 more variable: Zn_EPA3051 &lt;dbl&gt; This is a much more efficient way to calculate statistics. QUESTIONS: Calculate the maximum values for concentrations that were determined using EPA Method 3051. (HINT: change the function you call in the summarize statement.) Which of these metals has the maximum concentration you see, and in which region is it found? Calculate both the mean and maximum values for concentrations that were determined using the Mehlich3 test. (HINT: change the terms in the columns_to_include vector, as well as the function you call in the summarize statement.) Which of these metals has the highest average and maximum concentrations, and in which region are they found? "],["part-3.-visualizing-the-data.html", "Chapter 11 Part 3. Visualizing the Data", " Chapter 11 Part 3. Visualizing the Data Often, it can be easier to immediately interpret data displayed as a plot than as a list of values. For example, we can more easily understand how the arsenic concentration of the soil samples are distributed if we create histograms compared to looking at point values like mean, standard deviation, minimum, and maximum. One way to make histograms in R is with the hist() function. This function only requires that we tell R which column of the dataset that we want to plot. (However, we also have the option to tell R a histogram name and a x-axis label.) We can again use the pull() command and pipes (%&gt;%) to choose the column we want from the soil.values.clean dataset and make a histogram of them. This combination of commands follows the code structure: dataset %&gt;% pull(column_name) %&gt;% hist(main = chart_title, xlab = x_axis_title) soil.values.clean %&gt;% pull(As_EPA3051) %&gt;% hist(main = &#39;Histogram of Arsenic Concentration&#39;, xlab =&#39;Concentration in mg/kg&#39; ) We can see that almost all the soil samples had very low concentrations of arsenic (which is good news for the soil health!). In fact, many of them had arsenic concentrations close to 0, and only one sampling location appears to have high levels of arsenic. We might also want to graphically compare arsenic concentrations among the geographic regions in our dataset. We can do this by creating boxplots. Boxplots are particularly useful when comparing the mean, variation, and distributions among multiple groups. In R, one way to create a boxplot is using the boxplot() function. We don’t need to use pipes for this command, but instead will specify what columns we want to use from the dataset inside the boxplot() function itself. This command follows the code structure: boxplot(column_we’re_plotting ~ grouping_variable, data = dataset, main = “Title of Graph”, xlab = “x_axis_title”, ylab = “y_axis_title”) boxplot(As_EPA3051 ~ region, data = soil.values.clean, main = &quot;Arsenic Concentration by Geographic Region&quot;, xlab = &quot;Region&quot;, ylab = &quot;Arsenic Concentration in mg/kg&quot;) By using a boxplot, we can quickly see that, while one sampling site within Baltimore City has a very high concentration of arsenic in the soil, in general there isn’t a difference in arsenic content between Baltimore City and Montgomery County. QUESTIONS: Create a histogram for iron concentration, as well as a boxplot comparing iron concentration by region. Is the iron concentration similar among regions? Are there any outlier sites with unusually high or low iron concentrations? Create a histogram for lead concentration, as well as a boxplot comparing lead concentration by region. Is the lead concentration similar among regions? Are there any outlier sites with unusually high or low lead concentrations? Look at the maps for iron and lead on the BioDIGS website. Do the boxplots you created make sense, given what you see on these maps? Why or why not? "],["activity-questions.html", "Chapter 12 Activity Questions 12.1 Part 1. Examining the Data 12.2 Part 2. Summarizing the Data with Statistics 12.3 Part 3. Visualizing the Data", " Chapter 12 Activity Questions 12.1 Part 1. Examining the Data What data is found in the column labeled “Fe_Mehlich3”? Why would we be interested how much of this is in the soil? (You may have to search the internet for this answer.) What data is found in the column labeled “Base_Sat_pct”? What does this variable tell us about the soil? How many observations are in the soil testing values dataset that you loaded? What do each of these observations refer to? How many different regions are represented in the soil testing dataset? How many of them have soil testing data available? 12.2 Part 2. Summarizing the Data with Statistics All the samples from Baltimore City and Montgomery County were collected from public park land. The parks sampled from Montgomery County were located in suburban and rural areas, compared to the urban parks sampled in Baltimore City. Why might the Montgomery County samples have a lower average arsenic concentration than the samples from Baltimore City? What is the mean iron concentration for samples in this dataset? What about the standard deviation, minimum value, and maximum value? Calculate the mean iron concentration by region. Which region has the highest mean iron concentration? What about the lowest? Calculate the maximum values for concentrations that were determined using EPA Method 3051. (HINT: change the function you call in the summarize statement.) Which of these metals has the maximum concentration you see, and in which region is it found? Calculate both the mean and maximum values for concentrations that were determined using the Mehlich3 test. (HINT: change the terms in the columns_to_include vector, as well as the function you call in the summarize statement.) Which of these metals has the highest average and maximum concentrations, and in which region are they found? 12.3 Part 3. Visualizing the Data Create a histogram for iron concentration, as well as a boxplot comparing iron concentration by region. Is the iron concentration similar among regions? Are there any outlier sites with unusually high or low iron concentrations? Create a histogram for lead concentration, as well as a boxplot comparing lead concentration by region. Is the lead concentration similar among regions? Are there any outlier sites with unusually high or low lead concentrations? Look at the maps for iron and lead on the BioDIGS website. Do the boxplots you created make sense, given what you see on these maps? Why or why not? "],["about-the-authors.html", "About the Authors", " About the Authors These credits are based on our course contributors table guidelines.     Credits Names Pedagogy Content Developer Elizabeth Humphries Content Editors Ava Hoffman, Kate Isaac Project Directors Ava Hoffman, Michael Schatz, Jeff Leek, Frederick Tan Production Content Publisher Ira Gooding Technical Template Publishing Engineers Candace Savonen, Carrie Wright, Ava Hoffman Publishing Maintenance Engineer Candace Savonen Technical Publishing Stylists Carrie Wright, Candace Savonen Package Developers (ottrpal) John Muschelli, Candace Savonen, Carrie Wright Package Developer (BioDIGSData) Ava Hoffman Funding Funder National Human Genome Research Institute (NHGRI) Funding Staff Fallon Bachman, Jennifer Vessio, Emily Voeglein   ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.3.2 (2023-10-31) ## os Ubuntu 22.04.4 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Etc/UTC ## date 2025-02-21 ## pandoc 3.1.1 @ /usr/local/bin/ (via rmarkdown) ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## bookdown 0.41 2024-10-16 [1] CRAN (R 4.3.2) ## bslib 0.6.1 2023-11-28 [1] RSPM (R 4.3.0) ## cachem 1.0.8 2023-05-01 [1] RSPM (R 4.3.0) ## cli 3.6.2 2023-12-11 [1] RSPM (R 4.3.0) ## devtools 2.4.5 2022-10-11 [1] RSPM (R 4.3.0) ## digest 0.6.34 2024-01-11 [1] RSPM (R 4.3.0) ## ellipsis 0.3.2 2021-04-29 [1] RSPM (R 4.3.0) ## evaluate 0.23 2023-11-01 [1] RSPM (R 4.3.0) ## fastmap 1.1.1 2023-02-24 [1] RSPM (R 4.3.0) ## fs 1.6.3 2023-07-20 [1] RSPM (R 4.3.0) ## glue 1.7.0 2024-01-09 [1] RSPM (R 4.3.0) ## htmltools 0.5.7 2023-11-03 [1] RSPM (R 4.3.0) ## htmlwidgets 1.6.4 2023-12-06 [1] RSPM (R 4.3.0) ## httpuv 1.6.14 2024-01-26 [1] RSPM (R 4.3.0) ## jquerylib 0.1.4 2021-04-26 [1] RSPM (R 4.3.0) ## jsonlite 1.8.8 2023-12-04 [1] RSPM (R 4.3.0) ## knitr 1.48 2024-07-07 [1] CRAN (R 4.3.2) ## later 1.3.2 2023-12-06 [1] RSPM (R 4.3.0) ## lifecycle 1.0.4 2023-11-07 [1] RSPM (R 4.3.0) ## magrittr 2.0.3 2022-03-30 [1] RSPM (R 4.3.0) ## memoise 2.0.1 2021-11-26 [1] RSPM (R 4.3.0) ## mime 0.12 2021-09-28 [1] RSPM (R 4.3.0) ## miniUI 0.1.1.1 2018-05-18 [1] RSPM (R 4.3.0) ## pkgbuild 1.4.3 2023-12-10 [1] RSPM (R 4.3.0) ## pkgload 1.3.4 2024-01-16 [1] RSPM (R 4.3.0) ## profvis 0.3.8 2023-05-02 [1] RSPM (R 4.3.0) ## promises 1.2.1 2023-08-10 [1] RSPM (R 4.3.0) ## purrr 1.0.2 2023-08-10 [1] RSPM (R 4.3.0) ## R6 2.5.1 2021-08-19 [1] RSPM (R 4.3.0) ## Rcpp 1.0.12 2024-01-09 [1] RSPM (R 4.3.0) ## remotes 2.4.2.1 2023-07-18 [1] RSPM (R 4.3.0) ## rlang 1.1.4 2024-06-04 [1] CRAN (R 4.3.2) ## rmarkdown 2.25 2023-09-18 [1] RSPM (R 4.3.0) ## sass 0.4.8 2023-12-06 [1] RSPM (R 4.3.0) ## sessioninfo 1.2.2 2021-12-06 [1] RSPM (R 4.3.0) ## shiny 1.8.0 2023-11-17 [1] RSPM (R 4.3.0) ## stringi 1.8.3 2023-12-11 [1] RSPM (R 4.3.0) ## stringr 1.5.1 2023-11-14 [1] RSPM (R 4.3.0) ## urlchecker 1.0.1 2021-11-30 [1] RSPM (R 4.3.0) ## usethis 2.2.3 2024-02-19 [1] RSPM (R 4.3.0) ## vctrs 0.6.5 2023-12-01 [1] RSPM (R 4.3.0) ## xfun 0.48 2024-10-03 [1] CRAN (R 4.3.2) ## xtable 1.8-4 2019-04-21 [1] RSPM (R 4.3.0) ## yaml 2.3.8 2023-12-11 [1] RSPM (R 4.3.0) ## ## [1] /usr/local/lib/R/site-library ## [2] /usr/local/lib/R/library ## ## ────────────────────────────────────────────────────────────────────────────── "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
